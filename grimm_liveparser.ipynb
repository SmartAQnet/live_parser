{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from statistics import mode\n",
    "import datetime as dt\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "from basefunctions import ftpfunction as ftpfunc\n",
    "from basefunctions import parserfunctions as pf\n",
    "from basefunctions import grimmfunctions as grimm\n",
    "from basefunctions import requestfunction as requestfunc\n",
    "#from basefunctions import testfunctions as testfunc\n",
    "\n",
    "import saqncredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basefunctions Library:\n",
    "\n",
    "## parserfunctions as pf:\n",
    "\n",
    "### pf.getThingFromProperties(url, domain, serialno)\n",
    "\n",
    "function that uses url, operator domain and serialno as string inputs and returns the saqn database entry of the thing    \n",
    "\n",
    "### pf.post_difference(targetdatastream, dataframe)\n",
    "\n",
    "wrapper function that executes getSymmDiff and postObservations in succession\n",
    "\n",
    "### pf.getSymmDiff(targetdatastream, dataframe)\n",
    "\n",
    "function that checks a list of observations against existing observations in the database by timestamp input is targetdatastream, dataframe. returns an equally formatted, reduced dataframe of missing observations\n",
    "\n",
    "### pf.postObservations(targetdatastream, dataframe)\n",
    "\n",
    "function that posts observations to the server. returns a dictionary of counts of successfull and failed posts\n",
    "\n",
    "## grimmfunctions as grimm:\n",
    "\n",
    "### grimm.parseGrimmFile(filepath)\n",
    "\n",
    "function that grabs a file from the ftp server when given a path and parses it, returning a dataframe\n",
    "\n",
    "### grimm.formatDataframe(df,filepath)\n",
    "\n",
    "function that formats the dataframe such that column heads are identical to saqn observedproperty iot.ids input is dataframe, filepath (to identify device type)\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "    \n",
    "## OLD, not included\n",
    "\n",
    "### grimm.updateSoftwareNo(inputline,datastream)\n",
    "\n",
    "function that checks the [\"properties\"][\"software_version\"] field of a datastream with a new input of the form pd.Series({pandas timestamp, value}). mutates the datastream object (shallow copy!) and performs a patch request if necessary. returns the datastream so datastream=grimm.updateSoftwareNo(inputline,datastream) makes sense although the shallow copy should mutate it anyway\n",
    "\n",
    "--> probably belongs to pf library as it is not grimm specific\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## TODO\n",
    "\n",
    "- last calibration time to utc so that it is captured by the post function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messnetz\n",
      "------------------------\n",
      "NEW THING\n",
      "------------------------\n",
      "------------------------\n",
      "Messnetz/SN19006/2020-09-05-SN19006-measure.dat\n",
      "------------------------\n",
      "['None', 'None', 'None', 'None', 'None']\n",
      "------------------------\n",
      "Messnetz/SN19006/2020-09-06-SN19006-measure.dat\n",
      "------------------------\n",
      "['None', 'None', 'None', 'None', 'None']\n",
      "------------------------\n",
      "Messnetz/SN19006/2020-09-07-SN19006-measure.dat\n",
      "------------------------\n",
      "['None', 'None', 'None', 'None', 'None']\n",
      "------------------------\n",
      "Messnetz/SN19006/2020-09-08-SN19006-measure.dat\n",
      "------------------------\n",
      "['None', 'None', 'None', 'None', 'None']\n",
      "------------------------\n",
      "Messnetz/SN19006/2020-09-09-SN19006-measure.dat\n",
      "------------------------\n",
      "['None', 'None', {'success': 285, 'failed': 0}, {'success': 285, 'failed': 0}, {'success': 285, 'failed': 0}]\n",
      "------------------------\n",
      "Messnetz/SN19006/2020-09-10-SN19006-measure.dat\n",
      "------------------------\n",
      "['None', 'None', {'success': 283, 'failed': 0}, {'success': 283, 'failed': 0}, {'success': 283, 'failed': 0}]\n",
      "------------------------\n",
      "Messnetz/SN19006/2020-09-11-SN19006-measure.dat\n",
      "------------------------\n",
      "['None', 'None', {'success': 40, 'failed': 0}, {'success': 40, 'failed': 0}, {'success': 40, 'failed': 0}]\n",
      "------------------------\n",
      "Messnetz/SN19006/2020-09-12-SN19006-measure.dat\n",
      "------------------------\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\Paul\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\Paul\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\Paul\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 608, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\Paul\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Paul\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\Paul\\Documents\\SmartAQnet\\live_parser\\basefunctions\\parserfunctions.py\", line 227, in post_difference\n    symmdiff = getSymmDiff(targetdatastream, df_formatted)\n  File \"C:\\Users\\Paul\\Documents\\SmartAQnet\\live_parser\\basefunctions\\parserfunctions.py\", line 85, in getSymmDiff\n    obslist = json.loads(sess.get(targetquery).text)[\"value\"]\nKeyError: 'value'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d0d55d65415c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# for each datastream, check for missing observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_difference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargetdatastream\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_formatted\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtargetdatastream\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msaqndatastreams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    426\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'value'"
     ]
    }
   ],
   "source": [
    "#wrapper function for iteration. may also be parallelized or done in multiple serial calls\n",
    "\n",
    "# targeturl = \"http://193.196.38.108:8080/FROST-Server/v1.0\"\n",
    "targeturl = \"https://api.smartaq.net/v1.0\"\n",
    "operatordomain = \"grimm-aerosol.com\"\n",
    "\n",
    "folder = saqncredentials.grimm.folder\n",
    "things = ftpfunc.getData(folder)\n",
    "print(folder)\n",
    "\n",
    "#for thing in things[11:12]: \n",
    "for thing in ['SN19006']:\n",
    "\n",
    "    print(\"------------------------\")\n",
    "    print(\"NEW THING\")\n",
    "    print(\"------------------------\")\n",
    "    filelist=ftpfunc.getData(folder + \"/\" + thing)\n",
    "\n",
    "#     # reduce filelist so it contains the last 5 days plus the day 2 weeks ago\n",
    "#     today = dt.datetime.now()\n",
    "#     cropped_filelist = [file for file in filelist if dt.datetime.strptime(file[:10],'%Y-%m-%d')+ dt.timedelta(5) >= today]\n",
    "#     cropped_filelist += [file for file in filelist if (dt.datetime.strptime(file[:10],'%Y-%m-%d') + dt.timedelta(14)).date() == today.date()]\n",
    "#     print(cropped_filelist)\n",
    "    \n",
    "    for file in filelist:\n",
    "    # for file in cropped_filelist:\n",
    "        filepath = folder + \"/\" + thing + \"/\" + file\n",
    "        print(\"------------------------\")\n",
    "        print(filepath)\n",
    "        print(\"------------------------\")\n",
    "        \n",
    "        # get the file, parse it and format it for further progressing\n",
    "        df=grimm.parseGrimmFile(filepath)\n",
    "        df_formatted=grimm.formatDataframe(df,filepath)\n",
    "        \n",
    "        # Check Serial Number Column whether they are all the same\n",
    "        serialmode=mode(df_formatted[\"hardware.id\"])\n",
    "        \n",
    "        #check if the serial no that occurs most occurs more than 95% of the time. if yes, nonoccurence is considered a typo (throw warning in log but keep)\n",
    "        if(list(df_formatted[\"hardware.id\"]).count(serialmode)/len(list(df_formatted[\"hardware.id\"])) > 0.95 == False):\n",
    "            print(\"Warning: several serial numbers in one datasheet, needs manual inspection: \" + filepath)\n",
    "\n",
    "        \n",
    "        # get the database info corresponding to the thing and its datastreams\n",
    "        saqnthing = pf.getThingFromProperties(targeturl, **{\"operator.domain\": operatordomain}, **{\"hardware.id\": serialmode})\n",
    "        \n",
    "        sess = requestfunc.session(3, 2)\n",
    "        saqndatastreams = json.loads(sess.get(saqnthing[\"Datastreams@iot.navigationLink\"] + \"?$expand=ObservedProperty\").text)[\"value\"]\n",
    "\n",
    "        # for each datastream, check for missing observations\n",
    "        res=Parallel(n_jobs=2)(delayed(pf.post_difference)(targetdatastream,df_formatted) for targetdatastream in saqndatastreams)\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "\n",
    "#lat lon filter für historical locations? mit gutem statistischen algorithmus ist das rauszubekommen\n",
    "#-> FoI so lassen wäre ein interessanter datensatz für gps, allerdings sind dann die messdaten unbrauchbar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
