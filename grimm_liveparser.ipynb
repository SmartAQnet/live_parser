{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from statistics import mode\n",
    "import datetime as dt\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "from basefunctions import ftpfunction as ftpfunc\n",
    "from basefunctions import parserfunctions as pf\n",
    "from basefunctions import grimmfunctions as grimm\n",
    "#from basefunctions import testfunctions as testfunc\n",
    "\n",
    "import saqncredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basefunctions Library:\n",
    "\n",
    "## parserfunctions as pf:\n",
    "\n",
    "### pf.getThingFromProperties(url, domain, serialno)\n",
    "\n",
    "function that uses url, operator domain and serialno as string inputs and returns the saqn database entry of the thing    \n",
    "\n",
    "### pf.post_difference(targetdatastream, dataframe)\n",
    "\n",
    "wrapper function that executes getSymmDiff and postObservations in succession\n",
    "\n",
    "### pf.getSymmDiff(targetdatastream, dataframe)\n",
    "\n",
    "function that checks a list of observations against existing observations in the database by timestamp input is targetdatastream, dataframe. returns an equally formatted, reduced dataframe of missing observations\n",
    "\n",
    "### pf.postObservations(targetdatastream, dataframe)\n",
    "\n",
    "function that posts observations to the server. returns a dictionary of counts of successfull and failed posts\n",
    "\n",
    "## grimmfunctions as grimm:\n",
    "\n",
    "### grimm.parseGrimmFile(filepath)\n",
    "\n",
    "function that grabs a file from the ftp server when given a path and parses it, returning a dataframe\n",
    "\n",
    "### grimm.formatDataframe(df,filepath)\n",
    "\n",
    "function that formats the dataframe such that column heads are identical to saqn observedproperty iot.ids input is dataframe, filepath (to identify device type)\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "    \n",
    "## OLD, not included\n",
    "\n",
    "### grimm.updateSoftwareNo(inputline,datastream)\n",
    "\n",
    "function that checks the [\"properties\"][\"software_version\"] field of a datastream with a new input of the form pd.Series({pandas timestamp, value}). mutates the datastream object (shallow copy!) and performs a patch request if necessary. returns the datastream so datastream=grimm.updateSoftwareNo(inputline,datastream) makes sense although the shallow copy should mutate it anyway\n",
    "\n",
    "--> probably belongs to pf library as it is not grimm specific\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## TODO\n",
    "\n",
    "- last calibration time to utc so that it is captured by the post function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "NEW THING\n",
      "------------------------\n",
      "['2021-01-04-SN19006-measure.dat', '2021-01-05-SN19006-measure.dat', '2021-01-06-SN19006-measure.dat', '2021-01-07-SN19006-measure.dat', '2020-12-24-SN19006-measure.dat']\n",
      "------------------------\n",
      "Messnetz/SN19006/2021-01-04-SN19006-measure.dat\n",
      "------------------------\n",
      "------------------------\n",
      "Messnetz/SN19006/2021-01-05-SN19006-measure.dat\n",
      "------------------------\n",
      "------------------------\n",
      "Messnetz/SN19006/2021-01-06-SN19006-measure.dat\n",
      "------------------------\n",
      "------------------------\n",
      "Messnetz/SN19006/2021-01-07-SN19006-measure.dat\n",
      "------------------------\n",
      "------------------------\n",
      "Messnetz/SN19006/2020-12-24-SN19006-measure.dat\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "#wrapper function for iteration. may also be parallelized or done in multiple serial calls\n",
    "\n",
    "# targeturl = \"http://193.196.38.108:8080/FROST-Server/v1.0\"\n",
    "targeturl = \"https://api.smartaq.net/v1.0\"\n",
    "operatordomain = \"grimm-aerosol.com\"\n",
    "\n",
    "folder = saqncredentials.grimm.folder\n",
    "things = ftpfunc.getData(folder)\n",
    "\n",
    "\n",
    "for thing in things[11:12]: \n",
    "\n",
    "    print(\"------------------------\")\n",
    "    print(\"NEW THING\")\n",
    "    print(\"------------------------\")\n",
    "    filelist=ftpfunc.getData(folder + \"/\" + thing)\n",
    "\n",
    "    # reduce filelist so it contains the last 5 days plus the day 2 weeks ago\n",
    "    today = dt.datetime.now()\n",
    "    cropped_filelist = [file for file in filelist if dt.datetime.strptime(file[:10],'%Y-%m-%d')+ dt.timedelta(5) >= today]\n",
    "    cropped_filelist += [file for file in filelist if (dt.datetime.strptime(file[:10],'%Y-%m-%d') + dt.timedelta(14)).date() == today.date()]\n",
    "    print(cropped_filelist)\n",
    "    \n",
    "    for file in cropped_filelist:\n",
    "        filepath = folder + \"/\" + thing + \"/\" + file\n",
    "        print(\"------------------------\")\n",
    "        print(filepath)\n",
    "        print(\"------------------------\")\n",
    "        \n",
    "        # get the file, parse it and format it for further progressing\n",
    "        df=grimm.parseGrimmFile(filepath)\n",
    "        df_formatted=grimm.formatDataframe(df,filepath)\n",
    "        \n",
    "        # Check Serial Number Column whether they are all the same\n",
    "        serialmode=mode(df_formatted[\"hardware.id\"])\n",
    "        \n",
    "        #check if the serial no that occurs most occurs more than 95% of the time. if yes, nonoccurence is considered a typo (throw warning in log but keep)\n",
    "        if(list(df_formatted[\"hardware.id\"]).count(serialmode)/len(list(df_formatted[\"hardware.id\"])) > 0.95 == False):\n",
    "            print(\"Warning: several serial numbers in one datasheet, needs manual inspection: \" + filepath)\n",
    "\n",
    "        \n",
    "        # get the database info corresponding to the thing and its datastreams\n",
    "        saqnthing = pf.getThingFromProperties(targeturl,operatordomain,serialmode)\n",
    "        saqndatastreams = json.loads(requests.get(saqnthing[\"Datastreams@iot.navigationLink\"] + \"?$expand=ObservedProperty\").text)[\"value\"]\n",
    "\n",
    "        # for each datastream, check for missing observations\n",
    "        #res=Parallel(n_jobs=2)(delayed(pf.post_difference)(targetdatastream,df_formatted) for targetdatastream in saqndatastreams)\n",
    "        #print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODOs\n",
    "\n",
    "#lat lon filter für historical locations? mit gutem statistischen algorithmus ist das rauszubekommen\n",
    "#-> FoI so lassen wäre ein interessanter datensatz für gps, allerdings sind dann die messdaten unbrauchbar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
